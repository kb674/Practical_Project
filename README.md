# DevOps Core Practical Project

## Contents
* [Introduction](#introduction)
* [Application](#application)
* [Pipeline](#pipeline)
* [Pipeline Components](#pipeline-components)
* [Conclusion](#conclusion)

## INTRODUCTION

### Brief
The aim of this project is to create an app which generates an 'object'. Specifically the app architecture has to be service-oriented and composed of 4 services.
The final deliverable is a full CI pipeline which is triggered to test, build, push, configure and deploy the app.

### Requirements:
* Kanban Board - Trello Board
* Version Control System - Git
* Containerisation Tool - Docker
* Configuration Management - Ansible
* Orchestration Tool - Docker Swarm
* Reverse Proxy - NGINX 
* Live Environment - GCP VM

### App Idea
My initial idea was a 'fighter generator' application which would meet the following user stories:
* As a user I would like to randomly generate a fighter profile for fun.
* As a user I would like the profiles to not be serious.
* As a user I want to be able to refresh the page to create a fighter.
* As a user I want to be able to read my previously generated fighters.


## APPLICATION

### Front-end

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/front-end.png)

The front end acts as a server which displays information about a fighter in the form of a profile. Each profile displays a fighters name, the martial art they compete in and their record. The homepage displays the current fighter as well as the previously generated profiles. A fighter can be generated by refreshing the page.

### Architecture

The application implements a service oriented architecture in the form of 4 services which work together. 
* As explained above, service one acts as a server which displays fighter profiles. This is service one.
* Service two is an flask API which randomly generates a fighter name.
* Service three is also a flask API which randomly generates a martial art.
* Service four is a flask API which generates a number of wins based on the length of the fighter name and martial art put together.
* Finally there is the database which stores the generated name, martial and record in a MYSQL database. 

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/component%20diagram%202.png)

As illustrated in the above diagram:
* Service one sends a get request to service two. Service two responds with a fighter name. 
* Service one sends a get request to service three. Service three responds with a martial art.
* Service one then sends a post request to service four. Service four responds with the record of the fighter. This reponse is also a post request.
* Service one requests for all the data to be stored in the database. 
* Service one then displays this data.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/erd.png)

The database schema is shown above. The fighter name, martial art and record is stored in the fighters table. When service one displays all the fighter profiles, a select 
statement is run in the database and fetches the data from the fighters table. `` Example: SELECT * FROM fighters; ``

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/component%20diagram%20-%20old.png)

The original component-level diagram is linked above. I originally had the three APIs using get requests and had no database integration. After learning throughout the weeks in 
addition to further reflection, I figured out how to implement post requests for service four and integrate a database. These changes can be noticed in the final component 
diagram. With the final component-level design the app meets the criteria of an MVP.


## PIPELINE

A CI pipeline refers to a group of tools which work to together, giving developers the ability to quickly and easily implement new functionality to their applications.
My final pipeline allows for the automated testing, building, configuration and deployment of my fighter application, such that I can create new versions of the app very 
quickly.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/ci-pipeline-1.png)

Shown above is a diagram of my first CI pipeline. This particular pipeline is used in the early development of the project (See branches 5 and 6). As shown above, I initially 
imagined the pipeline to be a lot simpler than it actually turned out to be, specifically the deployment stage. Throughout the project I added major changes to the diagram 
as I learnt exactly how configuration and orchestration works and how these stages could be automated.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/ci-pipeline-3.png)

The final pipeline is shown above. This version demonstrates how Jenkins automates: pytest, docker build, docker push, ansible and docker swarm. Pushing to the main branch 
triggers a pipeline job. which is configured to use the jenkinsfile found in this repository.


## PIPELINE COMPONENTS

### Kanban Board and Risk Assessment

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/Risk-2.png)

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/Risk-3.png)

A risk assessment is very important to do during the planning phase of the project as it outlines potential risks and situations which could occur. By doing this in the 
beginning you can implement the control measures during the project and reduce risks. At the end of the project a review was carried out to see what actually occurred. The 
original and final assessments are shown above.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/Trello%20Board%20-1.png)

[Trello Board](https://trello.com/b/pUask7WA) was chosen for project tracking as it clearly displays all the tasks for a project and allows for Moscow prioritization to be 
easily assigned and seen. In this project I updated the trello board whenever I made a significant push to my repository. By using Moscow prioritization, I first worked on all 
the tasks needed to done to achieve a minimum viable product. This is evidenced by the tasks displayed in the completed backlog.

### VCS
Git and GitHub were chosen as the VSC and repository host respectively. Git was used specifically for its workflow capabilities. Throughout the project I used the feature branch 
workflow. For each big task I created a new branch and worked on this branch until the task or tasks were completed. Subsequently I created a pull request with the dev branch 
and merged these branches together. (Click the branch button for a full list of branches)

This method of working was very effective for this project as it suited the process of creating a pipeline. Creating a pipeline calls for individual components to work manually 
before trying to automate them. By working branch by branch I ended up with all components working smoothly by themselves which quickened the process of creating the pipeline 
and reduced the number of issues which occurred.

### Development
Python, specifically the web framework Flask was used to develope the application. Flask was chosen because it allows for simple implementation of create and read functionality. 
It was good choice for the project as creating APIs with it was simple which increased the speed of developement. As Flask is also lightweight, it meant the containerised 
services were relatively fast to build and run. 

### Testing

Python also allowed for APIs to be tested through unit mock testing. Unit testing is important because it gives us insight to how each function works, and if they work as 
intended. As part of my planning, I created a test specification which outlined the functionality I wanted to cover. 

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/test_specification.png)

The specification above shows which tests were implemented and which were not. A test was created for each service.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/coverage%20-%201%20-server.png)

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/coverage%20-%204%20-%20service_two.png)

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/coverage%20-%203%20-service_three.png)

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/coverage%20-%202%20-service_four.png)

The coverage of the tests is shown above. (90% or more)

The testing process was effective in finding issues with the application. An example of this was two lines of code in server/app.py.
````  
latest_profile = Fighters.query.order_by(Fighters.id.desc()).first()
all_profiles = Fighters.query.all()   
````
The code above queries for the latest profile before there is any data added to the database. This was leading to an error in the server test. By refactoring the code, I solved 
this issue and the test passed.

Refactored to not query the database but just display data.
````  
all_profiles = Fighters.query.all()
latest_profile = Fighters(name=fighter_name.text, art=martial_art.text, record=record.text)
````
If I was to improve the testing, I would implement integration tests to see how all the services work together. At this stage I am not testing the database layer and 
integration tests would also cover this. Finally, as seen in my test specification I did not write a test which successfully asserts the finish type in service four, this 
is something I would like to solve if I was working on the project longer.

### Jenkins automation
The Jenkinsfile has 5 stages which automate testing, building, pushing, configuration and deployment. Each stage has a respective script in the scripts folder. In general, the 
scripts first install the needed software for the stage to be carried out, like ansible for configuration and python3, python3-venv and python3-pip for testing. This makes the 
pipeline jobs portable. The scripts then carry out task specific commands. For example, the build and push scripts run a series of docker push and build commands respectively. 
`` docker build -t . ``
`` docker push [repo_name/image_name:latest] ``

(See each script in the scripts folder for all the specific commands)

### Ansible configuration and Deployment

Ansible is used to configure the live environment which is made up of 3 virtual machines: a NGINX VM, swarm-manager VM and swarm-worker VM. The playbook command is run in the 
configure script and installs docker on all three machines. By using ansible roles these make jobs more portable such that I should be able to run the pipeline on any 
machine. The playbook also runs two more roles which initiates a docker swarm on the manager VM and adds the worker to this swarm.

Once the configuration is setup the app can be deployed. The deploy script uses ``scp`` to send over the docker-compose file in this repository to the manager VM. The next 
commands uses SSH to run `` docker deploy stack --compose-file docker-compose yaml service`` on the manager VM which deploys the application to port 5000 on all nodes in the 
swarm.

The deploy script then runs another ``scp`` command to copy over the nginx.conf file to the NGINX VM. Subsequently, another SSH command is used to run a NGINX container with the 
nginx.conf as a bind mount. This sets up NGINX as a reverse proxy and load balancer. As a load balancer, NGINX reduces the risk of one node crashing due to too much user traffic 
by splitting traffic evenly between nodes.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/system-level-diagram.png)

This diagram illustrates the configuration of the live environment.

### Refactoring

Throughout the project there are times I had to refactor my code to make the pipeline work effectively:

* When first deploying my docker stack, there would essentially be two versions of the app running when refreshing the page. By changing the replicas of the DB container to 
one, this solved the issue.

* When first integrating the database layer I started off using a default MySQL image. This meant I still had to manually execute ``docker exec server python3 create.py``. By 
changing the compose file to build a custom mysql container solved this issue. The custom container copies in and runs a SQL dump file which pre creates the fighter table.


## CONCLUSION 

### Pipeline Run Time
For each deployment a log of the results is tabulated and the time taken to complete each stage is displayed.

![](https://github.com/kb674/Practical_Documentation/blob/main/Documentation/deployement-results.png)

As shown above, the average full run time of the pipeline so far is 1 minute and 45 seconds. Another noticeable fact is that the average time seems to decrease slightly from 
build 2 to build 5.

While there is a decrease in time, there are other steps which could be added to decrease the run time more significantly. 

### Future improvements to pipeline

If I had additional time to work on the pipeline, I would implement the following to decrease runtime:

* Nexus as a private image repository. By implementing this, all the images built would be cached and accessible on the local machine. This would noticeably speed up the build, 
push and deployment stages.

* Using docker-compose build --parallel. This command builds images at the same time and would decrease the run time of the build stage.

#

__Author:__

* Kushal Bhikhabhai

#

__Acknowledgements:__

* Ollie Nichols

* Harry Volker






